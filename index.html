<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>GridAI — Verifiable AI Execution</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="GridAI provides verifiable, replayable AI execution with cryptographic integrity.">
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 900px;
            margin: 40px auto;
            padding: 0 20px;
            line-height: 1.6;
            color: #111;
        }
        h1, h2 {
            color: #000;
        }
        hr {
            margin: 40px 0;
        }
        a {
            color: #0056b3;
            text-decoration: none;
            font-weight: bold;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<h1>GridAI</h1>
<p><strong>Verifiable AI execution with replayable trust.</strong></p>
<p>
GridAI captures, seals, and verifies AI runs so outcomes can be audited,
replayed, and independently trusted.
</p>

<hr>

<h2>What GridAI Does</h2>
<ul>
    <li>Runs AI workflows with complete execution logging</li>
    <li>Generates cryptographically sealed audit packs</li>
    <li>Replays and verifies historical runs with integrity checks</li>
</ul>

<hr>

<h2>Why GridAI Exists</h2>

<p>
As AI systems become more embedded in critical workflows, the question of trust becomes unavoidable.
Decisions driven by data must be verifiable, auditable, and explainable — not opaque.
</p>

<p>
GridAI was created to address this gap. It focuses on validating data integrity,
tracking trust signals, and producing evidence that outputs can be relied upon.
</p>

<p>
Rather than treating trust as an afterthought, GridAI treats it as a core system capability.
Every evaluation is designed to leave an audit trail that can be independently reviewed.
</p>

<p>
The demo available on this site illustrates this philosophy in practice.
</p>

<h2>How GridAI Approaches Trust</h2>

<p>
GridAI evaluates trust as a layered process rather than a single decision.
Each layer focuses on a different aspect of reliability.
</p>

<ul>
  <li>
    <strong>Data Integrity:</strong>
    Ensuring that input data has not been altered, corrupted, or inconsistently sourced.
  </li>
  <li>
    <strong>Evaluation Transparency:</strong>
    Making it clear how conclusions are reached, rather than presenting unexplained outputs.
  </li>
  <li>
    <strong>Traceability:</strong>
    Producing records that allow results to be reviewed, verified, and reproduced.
  </li>
</ul>

<p>
By separating trust into these components, GridAI avoids relying on a single opaque confidence score.
Instead, it produces structured signals that can be assessed independently.
</p>

<p>
This architecture allows GridAI to be used as a validation layer alongside existing systems,
rather than replacing them.
</p>

<section>
  <h2>Demo Scope & Limitations</h2>
  <p>
    This demonstration is a lightweight, client-side prototype designed to
    illustrate core trust concepts rather than a production-grade system.
  </p>
  <ul>
    <li>No real user data is collected or stored</li>
    <li>Hash verification is performed locally for transparency</li>
    <li>No blockchain or distributed ledger is used in this demo</li>
    <li>Results are illustrative and not legally binding</li>
  </ul>
  <p>
    The purpose of this demo is to communicate intent, architecture thinking,
    and responsible system design — not to simulate full-scale deployment.
  </p>
</section>

<section>
  <h2>Public Verifiability</h2>
  <p>
    GridAI is designed so that trust claims can be independently checked.
    This demo includes publicly verifiable artifacts to demonstrate that
    principle.
  </p>
  <ul>
    <li>Audit artifacts are published alongside each demo run</li>
    <li>Cryptographic hashes are provided for integrity checking</li>
    <li>Verification steps are documented and reproducible</li>
  </ul>
  <p>
    Anyone can independently validate the integrity of published demo artifacts
    using standard cryptographic tools.
  </p>
</section>

<section>
  <h2>Verify a Demo Download</h2>
  <p>
    This demo includes a downloadable artifact with a published cryptographic
    hash so that integrity can be independently verified.
  </p>

  <ol>
    <li>
      Download the demo file from the link above.
    </li>
    <li>
      Open PowerShell and navigate to the download folder.
    </li>
    <li>
      Run the following command:
      <pre><code>Get-FileHash gridai-trust-demo.txt -Algorithm SHA256</code></pre>
    </li>
    <li>
      Confirm the output hash matches the value published on this page.
    </li>
  </ol>

  <p>
    If the hashes match, the file has not been altered.
  </p>
</section>

<h2>Trust by Design</h2>
<p>
Every GridAI run produces a sealed audit bundle containing inputs,
outputs, hashes, and metadata. Any stakeholder can independently verify
that results have not been altered or tampered with.
</p>

<hr>

<h2>Download</h2>
<h3>What’s Included in the GridAI Demo</h3>

<p>
The GridAI demo package provides a practical example of how GridAI evaluates data trust,
validates integrity, and produces transparent verification output.
</p>

<ul>
  <li>Sample trust evaluation output</li>
  <li>Demonstration of integrity verification</li>
  <li>Clear, human-readable results</li>
</ul>

<p>
This demo is designed to be reviewed in under 5 minutes and requires no installation,
configuration, or external dependencies.
</p>

<p>
It is ideal for technical reviewers, analysts, and decision-makers who want a fast,
concrete understanding of GridAI’s approach.
</p>

<h3>Verify Your Download (Recommended)</h3>

<p>
For security and transparency, you can verify that your GridAI download has not been modified.
This ensures the file you downloaded is authentic and untampered.
</p>

<ol>
  <li>Open <strong>PowerShell</strong></li>
  <li>Navigate to the folder containing the downloaded file</li>
  <li>Run the following command:</li>
</ol>

<pre>
Get-FileHash gridai-trust-demo.txt -Algorithm SHA256
</pre>

<p>
The output hash should exactly match the value below:
</p>

<pre>
6F6F9E0182E79F8C510C155397BD921C0DD31A7033E2B06415A81EC4CDD83B1F
</pre>

<p>
If the hashes match, the file integrity is verified.
</p>
<p>
<strong>GridAI Trust Console (Windows)</strong><br>
<a href="#">Download coming shortly</a>
</p>
<p>
<em>SHA-256 checksums will be published for all releases.</em>
</p>

<hr>

<h2>Who This Is For</h2>
<ul>
    <li>Enterprises evaluating AI outputs</li>
    <li>Auditors and compliance teams</li>
    <li>Builders who require reproducibility and proof</li>
</ul>

<section id="trust">
  <h2>Download Integrity Verification</h2>
  <p>
    GridAI publishes cryptographic hashes for all distributed files.
    Users can independently verify file integrity before execution.
  </p>

  <h3>gridai-trust-demo.txt</h3>
  <pre>
SHA-256: 6F6F9E0182E79F8C510C155397BD921C0DD31A7033E2B06415A81EC4CDD83B1F
  </pre>

  <p>
    To verify on Windows:
  </p>
  <pre>
Get-FileHash gridai-trust-demo.txt -Algorithm SHA256
  </pre>
</section>

</body>
</html>
